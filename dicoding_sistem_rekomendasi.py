# -*- coding: utf-8 -*-
"""Dicoding: Sistem Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rrANQkUJgrtRCSxmzW4USIl9KEY04h-c

Nama: Zidni Iman Sholihati

Dicoding profil: [URL](https://www.dicoding.com/users/amirah_zidni)

Email: zidni.imani@gmail.com / m1821860@bangkit.academy

Kriteria submission:

1. Project merupakan hasil pekerjaan sendiri. 
2. Project belum pernah digunakan untuk submission kelas Machine Learning di Dicoding dan belum pernah dipublikasikan di platform manapun.
3. Dataset yang dipakai bebas, asal bisa digunakan untuk membuat sistem rekomendasi.
4. Memberikan dokumentasi menggunakan text cell pada notebook (.ipynb) untuk menjelaskan setiap tahapan proyek seperti pada contoh berikut: contoh proyek dengan dokumentasi. 
5. Menentukan solusi permasalahan dengan memilih pendekatan berikut:
  - Content-based Filtering
  - Collaborative Filtering
6. Membuat draf laporan proyek machine learning yang menjelaskan alur proyek Anda mulai dari project overview, business understanding, data understanding, data preparation, modeling, hingga tahap evaluasi. Ketentuan draf laporan proyek machine learning dapat Anda lihat pada sub modul berikutnya tentang Detail Laporan.

Saran submission:
* Menerapkan Rubrik/Kriteria Penilaian (Tambahan) untuk mendapatkan skala penilaian (bintang) yang lebih tinggi.

# Project Overview
Proyek *machine learning* ini akan membahas tentang **"Sistem Rekomendasi Buku dengan Content Based Filtering dan Collaborative Filtering"**.

![banner](https://raw.githubusercontent.com/ZidniImani/recommender-system/main/images/banner.png?token=AQMCDSGER6CZT5SGRLZPXWDBQOMKI "banner")

Membaca buku adalah salah satu kegiatan yang belum banyak peminatnya di Indonesia. Padahal membaca adalah jendela ilmu. Bahkan salah satu segmen pasar awal e-commerce Amazon adalah pasar buku sebelum akhirnya meluaskan target pasar ke segmen lainnya. Dalam e-commerce Amazon, tentunya terdapat sistem rekomendasi yang membantu pengunjung mencari buku agar pengunjung website tersebut membuat keputusan akhir yaitu membelinya [[1]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.9764&rep=rep1&type=pdf). Sistem rekomendasi buku juga dapat membantu pembaca buku mengetahui informasi buku-buku yang akan dibaca selanjutnya sesuai dengan preferensi pengguna dari rekam jejak buku yang telah dibaca sebelumnya. Terjadi keuntungan dua pihak karena konsumen mendapatkan informasi yang diperlukan untuk membuat suatu keputusan sementara dari pemilik bisnis juga mendapatkan profit dari penjualan. Hal ini menjadikan sistem rekomendasi telah digunakan secara luas oleh hampir semua area bisnis. [[2]](https://ejournal.akprind.ac.id/index.php/technoscientia/article/view/612).

Pada proyek machine learning ini, sistem rekomendasi yang akan dibuat memiliki fokus pada sistem rekomendasi buku karena di Indonesia sendiri masih diperlukan sebuah sistem yang dapat membantu merekomendasikan para pembaca agar lebih mudah mendapatkan informasi buku-buku yang akan dibaca selanjutnya. Hal ini didasarkan pada hasil survey kemampuan membaca oleh PISA tahun 2018 yang menghasilkan nilai skor membaca pelajar Indonesia yang masih sangat rendah [[3]](https://www.oecd.org/education/pisa-2018-results-volume-i-5f07c754-en.htm).

# Business Understanding
Membaca adalah salah satu kegiatan mengumpulkan informasi serta memahami makna dari sebuah tulisan. Manfaat membaca diantaranya adalah meningkatkan kapasitas berpikir dan meningkatkan keterampilan menulis. Selain itu, membaca juga dapat menjadi kegiatan hiburan atau kegiatan yang mampu menenangkan pikiran karena sebuah bacaan dapat membawa pembacanya ke dunia imajinasi luas dalam konteks atau tema yang diangkat. Sehingga tak jarang apabila setelah membaca buku timbul keinginan untuk melanjutkan ke bacaan lainnya yang memiliki relasi atau kemiripan dengan bacaan sebelumnya.

![journey](https://img.freepik.com/free-psd/every-book-is-new-wonderful-travel-quote-with-books_23-2148355614.jpg?size=626&ext=jpg)

Keinginan ini membuat pembaca buku akan mencari preferensi buku bacaan selanjutnya yang serupa atau memiliki relasi terhadap buku yang telah dibaca. Relasi atau kesamaan tersebut dapat berupa kelanjutan isi buku atau kesamaan penulis buku. Harapannya adalah agar pembaca mendapatkan informasi lanjutan atau kesamaan sensasi membaca dari buku yang akan dibaca selanjutnya. Sistem rekomendasi dapat menjadikan salah satu solusi dari keperluan pembaca untuk mencari buku selanjutnya karena sistem rekomendasi mampu menghasilkan informasi-infomasi buku yang memiliki kemiripan dengan suatu preferensi tertentu. 

## Problem Statements

Dari latar belakang di atas, dapat ditarik rumusan masalah sebagai berikut:
1. Sistem rekomendasi apa yang baik untuk diterapkan dalam konteks pemberian rekomendasi buku?
2. Bagaimana cara membuat sistem rekomendasi bagi pembaca buku?

## Goals
Tujuan proyek yang ingin dicapai adalah:
1. Menentukan sistem rekomendasi buku yang hasilnya relevan dengan pembaca buku.
2. Membuat sistem rekomendasi buku bagi pembaca buku.

## Solution Approach
Pendekatan solusi untuk mencapai *Goals* di atas dapat dijabarkan dalam langkah-langkah berikut:
1. Mengunduh data tentang rekomendasi buku.

    Data diunduh dari Kaggle dengan tautan berikut [Book Recommendation Dataset](https://www.kaggle.com/arashnic/book-recommendation-dataset).
2. Melakukan pra-pemrosesan data.

    Pra-pemrosesan data diperlukan agar data yang akan diumpankan pada model *machine learning* tidak memiliki bias atau mengalami kegagalan memprediksi rekomendasi. Pra-pemrosesan data pada proyek ini adalah:
      - **Mengganti nama kolom** dengan nama yang bisa digunakan dalam pengolahan lanjutan yakni mengubah strip (-) dengan garis bawah (_).
      - **Memperbaiki nilai** dari baris yang terdapat kesalahan ketik atau nilai abnormal.
      - **Menghapus kolom yang tidak diperlukan** seperti kolom gambar.
      - **Menghapus baris** yang memiliki nilai kosong.
3. Melakukan persiapan data.

    Persiapan data pada proyek ini dilakukan untuk mempersiapkan data sebelum digunakan untuk melatih model sistem rekomendasi. Persiapan data diantaranya adalah:
      - **Menggabungkan data** berdasarkan nilai kolom kunci.
      - **Menghapus baris** yang tidak memiliki nilai setelah digabungkan.
      - **Mengelompokkan dan mengurutkan data** berdasarkan rating.
      - **Mengambil sampel data** karena data ini terlalu besar dan menghabiskan banyak sumber daya RAM yang dapat menghasilkan *notebook crash* pada Google Colab proyek ini.
4. Membangun sistem rekomendasi.

    Sistem rekomendasi yang diajukan untuk menyelesaikan permasalahan ini adalah penggunaan dua algoritma *Content Based Filtering* dan *Collaborative Filtering*.
    - **Content Based Filtering**. Dalam konteks penelitian ini dan berdasarkan sumber [[2]](https://ejournal.akprind.ac.id/index.php/technoscientia/article/view/612), algoritma *content based filtering* bekerja dengan mencari kedekatan suatu buku yang akan direkomendasikan dengan buku yang telah diambil oleh pembaca berdasarkan kemiripan antar isinya.
        - Kelebihan:
            - Hasil rekomendasi didasarkan pada preferensi buku.
            - Sederhana dan transparan karena mudah dipahami bagaimana algoritma ini bekerja.
        - Kelemahan:
            - Pembaca buku tidak mendapatkan rekomendasi dari jenis buku yang berbeda.
    - **Collaborative Filtering**. Algoritma *collaborative filtering* dalam konteks penelitian ini bekerja dengan mengumpulkan dan mengolah sejumlah besar informasi yang didasarkan pada aktifitas pembaca buku seperti pemberian nilai, penulis buku, atau preferensi lainnya. Informasi yang telah dikumpulkan dan diolah tersebut akan digunakan sebagai preferensi dengan pembaca buku lain dengan mencari kesamaannya.
        - Kelebihan:
            - Informasi tentang preferensi dapat ditambahkan secara mudah.
            - Adanya rekam jejak preferensi memudahkan sistem rekomendasi bekerja lebih baik.
        - Kelemahan:
            - Kurang efektif terhadap pengguna yang belum memiliki data karena tidak terdapat informasi yang cukup.
5. Melakukan evaluasi hasil sistem rekomendasi.

    Tahap ini dilakukan untuk mengukur seberapa baik hasil sistem rekomendasi. Berdasarkan algoritma yang akan digunakan, evaluasi yang bisa diterapkan adalah nilai presisi >80% pada algoritma *content based filtering* dan nilai RMSE (*Root Mean Squared Error*) <10% skala data pada algoritma *collaborative filtering*.

# Data Understanding
Dataset proyek ini berasal dari platform Kaggle yang dipublikasi oleh MÃ¶bius dengan judul [Book Recommendation Dataset](https://www.kaggle.com/arashnic/book-recommendation-dataset). Berdasarkan metadata, dataset ini dikumpulkan oleh Cai-Nicolas Ziegler di tahun 2004 yang bersumber dari komunitas [bookcrossing](
https://www.bookcrossing.com/howto). Terdapat tiga buah dataset yaitu Books.csv, Ratings.csv, dan Users.csv.

Books.csv adalah data mengenai buku dengan 8 kolom dengan keterangan sebagai berikut:

| Kolom               | Deskripsi                                                                                      |
| --------------------| ---------------------------------------------------------------------------------------------- |
| ISBN                | *International Standard Book Number* atau deretan 13 digit angka nomor identifikasi buku.      |
| Book-Title          | Judul buku.                                                                                    |
| Book-Author         | Penulis Buku.                                                                                  |
| Year-Of-Publication | Tahun publikasi buku.                                                                          |
| Publisher           | Penerbit buku.                                                                                 |
| Image-URL-S         | Alamat URL cover buku ukuran kecil.                                                            |
| Image-URL-M         | Alamat URL cover buku ukuran menengah.                                                         |
| Image-URL-L         | Alamat URL cover buku ukuran besar.                                                            |


Dalam dataset Ratings.csv yang berisi informasi peringkat buku terdapat 3 kolom dengan keterangan berikut:

| Kolom               | Deskripsi                                                                                        |
| --------------------| ------------------------------------------------------------------------------------------------ |
| User-ID             | Nomor identifikasi *user* atau pemberi nilai buku.                                                    |
| ISBN                | *International Standard Book Number* atau deretan 13 digit angka nomor identifikasi buku.        |
| Book-Rating         | Nilai buku yang diberikan *user*. Berisi rentang nilai 0-10 (semakin tinggi semakin baik) sebagai penilaian eksplisit dan nilai 0 sebagai penilaian implisit.              |

Terakhir, dalam dataset Users.csv yang berisi informasi tentang *user* atau pemberi nilai buku terdapat 3 kolom dengan keterangan berikut:

| Kolom               | Deskripsi                                                                            |
| --------------------| ------------------------------------------------------------------------------------ |
| User-ID             | Nomor identifikasi *user* atau pemberi nilai buku.                                        |
| Location            | Lokasi *user* (kota, negara bagian, dan negara). |
| Age                 | Usia *user* atau pemberi nilai buku.                                                      |
"""

# Library pengolahan data
import zipfile
import pandas as pd
import numpy as np
from zipfile import ZipFile

# Library visualisasi data
import matplotlib.pyplot as plt
import seaborn as sns

# Library machine learning sistem rekomendasi
import tensorflow as tf
import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tensorflow import keras
from tensorflow.keras import layers

# Library evaluasi data
from sklearn.metrics import mean_squared_error

"""## 1) Mengambil Dataset"""

# Mengambil data kaggle
!chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/
!kaggle datasets download arashnic/book-recommendation-dataset

# Unzip file
zip_file = '/content/book-recommendation-dataset.zip'
with zipfile.ZipFile(zip_file, 'r') as zip:
  zip.extractall('/content')

"""## 2) Exploratory Data Analysis

### Books
"""

# Load Books.csv ke df_buku
url = '/content/Books.csv'
df_buku = pd.read_csv(url)
df_buku.sample(5)

# Melihat informasi kolom df_buku
df_buku.info()

"""Umumnya kita bisa langsung melihat visualisasi distribusi penyebaran nilai dari kolom tahun terbit (Year-Of-Publication) tetapi setelah diperiksa terdapat kesalahan tipe data pada kolom tersebut yang seharusnya int tetapi justru *object*. Ada kemungkinan terdapat kesalahan nilai di dalamnya yang akan diperiksa pada proses selanjutnya."""

# Melihat nilai kosong df_buku
df_buku.isna().sum()

# Memeriksa nilai yang ada pada kolom Year-Of-Publication
print(df_buku['Year-Of-Publication'].unique())

# Melihat jumlah nilai unik pada judul, penerbit, dan penulis buku
print('Banyak judul buku: ', len(df_buku['Book-Title'].unique()))
print('Banyak penerbit: ', len(df_buku['Publisher'].unique()))
print('Banyak penulis buku: ', len(df_buku['Book-Author'].unique()))

"""Terdapat 271.360 baris pada informasi df_buku tetapi hanya terdapat 242.135 judul buku. Mari kita lihat nilai duplikat pada Book-Title untuk memahami lebih dalam:"""

# Melihat nilai duplikat dari judul buku
df_buku[df_buku['Book-Title'].duplicated()].sample(3)

# Mengambil seluruh baris yang berisi salah satu judul buku duplikat di atas (cell sebelumnya)
df_buku[df_buku['Book-Title'] == 'A Member of the Family']

"""Dari eksplorasi data Books.csv ini dapat kita simpulkan bahwa:

1. Sebuah buku dapat memiliki lebih dari satu ISBN. Hal ini dapat menjadikan dasar untuk mengelompokkan atau menghimpun data berdasarkan judul buku.
2. Data Books.csv memiliki 271.360 baris dan 8 kolom.
3. Terdapat nilai kosong pada kolom Book-Author, Publisher, dan Image-URL-L.
4. Terdapat kesalahan nilai pada kolom Year-Of-Publication.

### Ratings
"""

# Load Rating.csv ke df_rate
url = '/content/Ratings.csv'
df_rate = pd.read_csv(url)
df_rate.tail(5)

# Melihat informasi kolom df_rate
df_rate.info()

# Melihat nilai kosong pada df_buku
df_rate.isna().sum()

# Melihat jumlah nilai unik kolom User-ID dan ISBN pada df_buku
print('Banyak user memberi rate: ', len(df_rate['User-ID'].unique()))
print('Banyak buku diberi rate', len(df_rate['ISBN'].unique()))

# Melihat isi rate yang diberikan user
print('Rating yang diberikan', df_rate['Book-Rating'].unique())

# Visualisasi distribusi penyebaran penilaian user
sns.countplot(data=df_rate , x='Book-Rating')

"""Dari eksplorasi data Ratings.csv, dapat kita simpulkan bahwa:

1. Distribusi Book-Rating memiliki nilai 0 cukup banyak. Menurut metadata, nilai 0 ini adalah penilaian implisit yang perlu dilakukan pengolahan di proses selanjutnya untuk membedakan penilaian eksplisit.
2. Data ini memiliki 1.149.780 baris dan 3 kolom.
3. Tidak terdapat nilai kosong pada data ini.

### Users
"""

# Load Users.csv ke df_user
url = '/content/Users.csv'
df_user = pd.read_csv(url)
df_user.sample(5)

# Melihat informasi df_user
df_user.info()

# Menghitung nilai kosong pada df_user
df_user.isna().sum()

# Melihat jumlah nilai unik kolom User-ID dan lokasi pada df_user
print('Banyak user: ', len(df_user['User-ID'].unique()))
print('Banyak lokasi user', len(df_user['Location'].unique()))

# Melihat distribusi nilai pada Age
sns.histplot(data=df_user , x='Age')
plt.title('Distribusi Usia',size=16)
plt.show()

"""Dari grafik, rentang yang diberikan cukup luas dari 0 sampai 250. Untuk sementara dapat disimpulkan bahwa terdapat nilai abnormal yang akan kita proses di tahap selanjutnya."""

# Melihat isi Age user
print('Umur (Age) user: ', df_user['Age'].unique())

# Melihat contoh nilai abnormal dengan usia 204
df_user[df_user['Age'] == 204]

"""Dari eksplorasi data Users.csv, dapat kita simpulkan bahwa:

1. Distribusi nilai Age pada data Users.csv memiliki skewness positif dan terdapat nilai abnormal yang akan kita proses di tahap selanjutnya.
2. Data ini memiliki 278.858 baris dan 3 kolom.
3. Terdapat nilai kosong pada kolom Age.

# Data Preparation

## 3) Mengganti Nama Kolom
"""

# Mengganti nama kolom agar mudah digunakan dalam pemrosesan berikutnya
df_buku.rename(columns={
    'Book-Title':'book_title',
    'Book-Author':'book_author',
    'Year-Of-Publication':'year_of_publication'
    },inplace=True)
df_rate.rename(columns={
    'User-ID':'user_id',
    'Book-Rating':'book_rating'
    },inplace=True)
df_user.rename(columns={
    'User-ID':'user_id'
    },inplace=True)

"""## 4) Memperbaiki Nilai"""

# Setting agar menampilkan kolom secara penuh
pd.set_option('display.max_columns', None)
pd.set_option("display.max_colwidth", None)

# Memeriksa nilai abnormal agar mendapat index-nya
df_buku[df_buku['year_of_publication'].isin(['Gallimard', 'DK Publishing Inc'])]

# Memperbaiki nilai df_buku di index 209538, 220731, 221678
df_buku.loc[[209538],'year_of_publication'] = 2000
df_buku.loc[[209538],'book_author'] = 'Michael Teitelbaum'
df_buku.loc[[209538],'Publisher'] = 'DK Publishing Inc'
df_buku.loc[[209538],'book_title'] = 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'

df_buku.loc[[220731],'year_of_publication'] = 2003
df_buku.loc[[220731],'book_author'] = 'Jean-Marie Gustave Le ClÃ?ÃÂ©zio'
df_buku.loc[[220731],'Publisher'] = 'Gallimard'
df_buku.loc[[220731],'book_title'] = 'Peuple du ciel, suivi de \'Les Bergers'

df_buku.loc[[221678],'year_of_publication'] = 2000
df_buku.loc[[221678],'book_author'] = 'James Buckley'
df_buku.loc[[221678],'Publisher'] = 'DK Publishing Inc'
df_buku.loc[[221678],'book_title'] = 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'

# Preprocessing kolom year_of_publication
## Mengganti kolom ke integer
df_buku['year_of_publication'] = df_buku['year_of_publication'].astype(int)

## Menganti nilai abnormal
df_buku.loc[(df_buku.year_of_publication <= 1960) |
            (df_buku.year_of_publication >= 2006)
            ,'year_of_publication'] = round(df_buku.year_of_publication.value_counts().idxmax())

df_buku.info()

# Menampilkan nilai year_of_publication setelah dikoreksi
print(df_buku['year_of_publication'].unique())

# Memperbaiki nilai abnormal pada Age
df_user.loc[(df_user.Age <= 5) |
            (df_user.Age >= 90)
            ,'Age'] = round(df_user.Age.value_counts().idxmax())

# Menampilkan distribusi year_of_publication
sns.histplot(df_buku['year_of_publication'])
plt.xlabel('Year Of Publication',size=14)
plt.title('Histogram Tahun Publikasi Setelah Pra-pemrosesan',size=16)
plt.show()

"""## 5) Menghapus Baris Nilai Kosong

### Books
"""

# Menampilkan jumlah nilai kosong pada df_buku
df_buku.isna().sum()

# Drop baris dari df_buku yg memiliki nilai empty 
df_buku = df_buku.dropna()

# Menampilkan kembali jumlah nilai kosong pada df_buku
df_buku.isna().sum()

"""### Ratings"""

# Drop baris yg memiliki nilai rating 0 pada kolom book_rating dalam df_rate
# Saat ini belum cukup informasi untuk mengolah penilaian implisit.
index = df_rate.loc[df_rate['book_rating']==0].index
df_rate.drop(index,inplace=True)

# Menampilkan visualisasi distribusi nilai pada book_rating
sns.countplot(data=df_rate , x='book_rating')
plt.title('Distribusi Rating',size=16)
plt.show()

"""### Users"""

# Menampilkan jumlah nilai kosong pada df_user
df_user.isna().sum()

# Drop baris yg memiliki nilai empty pada df_user
df_user = df_user.dropna()

# Menampilkan distribusi nilai Age setelah pra pemrosesan
sns.histplot(data=df_user , x='Age')
plt.title('Distribusi Usia Setelah Pra-pemrosesan',size=16)
plt.show()

# Melihat kembali isi Age df_user
print('Umur (Age) user: ', df_user['Age'].unique())

# Memeriksa kembali nilai kosong df_buku
df_buku.isna().sum()

"""## 6) Menghapus Kolom yang Tidak Diperlukan

"""

# Drop kolom gambar pada df_buku
df_buku.drop(['Image-URL-S','Image-URL-M','Image-URL-L'],axis=1,inplace=True)

# Drop kolom Location pada df_user
df_user.drop(['Location'],axis=1,inplace=True)

"""## 7) Menggabungkan Data"""

# Menggabungkan seluruh data
df = pd.merge(df_rate, df_user[['user_id', 'Age']], on='user_id')
df = pd.merge(df, df_buku[['book_title', 'ISBN', 'book_author', 'year_of_publication','Publisher']], on='ISBN')

# Menampilkan informasi data yang telah digabungkan
df.info()

# Memeriksa kembali nilai kosong pada df yang telah digabungkan
df.isnull().sum()

"""Terlihat tidak ada data kosong yang menandakan tidak perlu pembersihan kembali. Sebelum melanjutkan, kita bisa melihat daftar buku berdasarkan book_rating dan menampilkan data berdasarkan urutan buku yang diberikan penilaian buku paling tinggi."""

# Menampilkan 10 buku yang diberikan penilaian paling banyak
df[['book_title', 'book_rating']].groupby('book_title').sum().sort_values('book_rating', ascending=False).head(10)

"""## 8) Mengelompokkan dan Mengurutkan Data"""

# Menghimpun/mengelompokkan data berdasarkan book_title
df = df.groupby('book_title', as_index=False).agg({
    'user_id':'first',
    'ISBN':'first',
    'book_rating':'sum', # menghitung total jumlah book_rating
    'Age':'first',
    'book_title':'first',
    'book_author':'first',
    'year_of_publication':'first',
    'Publisher':'first',
    }).sort_values('book_rating', ascending=False) # diurutkan berdasarkan book_rating
df

"""## 9) Mengambil Sampel Data"""

# Mengambil 10.000 baris dari df sebagai sample
df_sample = df.sample(10000).copy()

# Menampilkan baris unik df_sample
print(len(df_sample.book_title.unique()))    # Jumlah judul buku
print(len(df_sample.ISBN.unique()))          # Jumlah ISBN
print(len(df_sample.user_id.unique()))       # Jumlah user id
print(len(df_sample.Publisher.unique()))     # Jumlah penerbit
print(len(df_sample.book_author.unique()))   # Jumlah penulis buku

df_sample.describe()

"""## 10) Encoding Fitur"""

# Encoding fitur user_id dan isbn
# Fitur user_id
user_id = df_sample['user_id'].unique().tolist()
encoded_user_id = {x: i for i, x in enumerate(user_id)}

# Fitur ISBN 
isbn = df_sample['ISBN'].tolist()
encoded_isbn = {x: i for i, x in enumerate(isbn)}
isbn_encoded_to_isbn = {i: x for i, x in enumerate(isbn)}

# Memetakan user_id dan isbn ke df_sample
df_sample['encoded_user'] = df_sample['user_id'].map(encoded_user_id)
df_sample['encoded_isbn'] = df_sample['ISBN'].map(encoded_isbn)

# Mendapatkan jumlah user serta isbn
num_users = len(encoded_user_id)
num_isbn = len(isbn_encoded_to_isbn)
 
# Mengubah book_rating menjadi nilai float
df_sample['book_rating'] = df_sample['book_rating'].values.astype(np.float32)
 
# Nilai minimum serta maksimum book_rating
min_rating = min(df_sample['book_rating'])
max_rating = max(df_sample['book_rating'])

# Lihat hasilnya
print('Minimal Rating: {}\nMaksimal Rating: {}'.format(
    min_rating, max_rating
))

# Lihat kembali data df_sample
print(df_sample.info())
df_sample.head()

"""## 11) Pembagian Dataset"""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df_sample[['encoded_user', 'encoded_isbn']].values
 
# Membuat variabel y untuk membuat rating dari hasil dengan scaling
y = df_sample['book_rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
split_size = int(0.8 * df_sample.shape[0])
x_train, x_val, y_train, y_val = (
    x[:split_size],
    x[split_size:],
    y[:split_size],
    y[split_size:]
)

"""# Modeling

## 12) Membuat Model dengan Content Based Filtering
"""

# Membuat dataframe baru untuk Content Based Filtering (CBF)
df_new = pd.DataFrame({
    'ISBN': df_sample['ISBN'].tolist(),
    'book_title': df_sample['book_title'].tolist(),
    'book_author': df_sample['book_author'].tolist()
})
df_new.head()

# Mempersiapkan TF IDF
tfidf = TfidfVectorizer()
tfidf.fit(df_new['book_author'])

# Mengubah dalam bentuk matriks TF IDF
tfidf_matrix = tfidf.fit_transform(df_new['book_author'])

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom dari judul buku
cosine_sim_df = pd.DataFrame(cosine_sim,
                             index=df_new['book_title'],
                             columns=df_new['book_title'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def book_recommendations(nama_buku, similarity_data=cosine_sim_df, items=df_new[['book_title', 'book_author']], k=5):
    """
    Rekomendasi buku berdasarkan kemiripan dataframe
 
    Parameter:
    ---
    nama_buku : tipe data string (str)
                Nama Buku (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan buku sebagai indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---

    Pada index ini, kita mengambil k dengan nilai similarity terbesar 
    pada index matrix yang diberikan (i).
    """
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_buku].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_buku agar nama resto (key) yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_buku, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

nama_buku = df_new.sample(1).iloc[0]
print("Judul buku: ",nama_buku.book_title)
print("Penulis buku: ",nama_buku.book_author)

print("Buku yang mungkin disukai berdasarkan penulis buku yang sama")
book_recommendations(nama_buku.book_title)

"""## 13) Membuat Model dengan Collaborative Filtering"""

# Membuat class RecommenderNet
class RecommenderNet(tf.keras.Model):
  # Insialisasi fungsi
  def __init__(self, num_users, num_isbn, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_isbn = num_isbn
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias

    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_isbn,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.resto_bias = layers.Embedding(num_isbn, 1) # layer embedding resto bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2

    resto_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    resto_bias = self.resto_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2) 
 
    x = dot_user_resto + user_bias + resto_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

# Membuat model dari class RecommenderNet
model = RecommenderNet(num_users, num_isbn, 50) # inisialisasi model
 
# Compile model
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)
# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val),
    verbose = 1
)

# Menampilkan hasil training
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])

plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'])
plt.show()

# Mengambil sampel user
user_id = df_sample.user_id.sample(1).iloc[0]
read_book = df_sample[df_sample.user_id == user_id]

unread_book = df_sample[~df_sample['ISBN'].isin(read_book.ISBN.values)]['ISBN'] 
unread_book = list(
    set(unread_book)
    .intersection(set(encoded_isbn.keys()))
)
 
unread_book = [[encoded_isbn.get(x)] for x in unread_book]
user_encoder = encoded_user_id.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(unread_book), unread_book)
)

ratings = model.predict(user_book_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_isbn = [
    isbn_encoded_to_isbn.get(unread_book[x][0]) for x in top_ratings_indices
]
# Menampilkan hasilnya
print('Menampilkan rekomendasi untuk pembaca dengan User-ID: {}'.format(user_id))
print('===' * 12)
print('Buku yang diberikan nilai tinggi:')
 
top_book_user = (
    read_book.sort_values(
        by = 'book_rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
 
buku_df = df_sample[df_sample['ISBN'].isin(top_book_user)]
for row in buku_df.itertuples():
    print('-',row.book_title, ':', row.book_author)

print('----' * 10)
print('10 buku rekomendasi:')
print('----' * 10)
 
buku_rekomendasi = df_sample[df_sample['ISBN'].isin(recommended_isbn)]
for row in buku_rekomendasi.itertuples():
    print(row.book_title, ':', row.book_author)

"""# Evaluation

## 14) Evaluasi dengan Precision

- *Precision* atau presisi adalah metriks evaluasi untuk mengukur pola positif yang diprediksi dengan benar dari total pola prediksi dalam kelas positif. Kelebihan presisi adalah mampu menilai prediksi model terhadap label data positif. Ini menghasilkan kelemahan presisi yang tidak mampu mengukur hasil label negatif.

  ![precision](https://user-images.githubusercontent.com/68690376/139575828-21a60c1f-2373-4e0c-914b-ad7b81960601.png)
  
  Dengan catatan tp adalah *true positive* atau nilai label positif yang diprediksi benar dan fp adalah *false positive* atau nilai label negatif yang diprediksi salah.
  
  ![CBFresult](https://user-images.githubusercontent.com/68690376/139575267-9ca8e281-2384-4476-ae21-f426daf9d7f0.png)
  
  Hasil presisi dalam contoh sebelumnya bernilai tp = 4 dan fp = 1. Berarti *precision* bernilai:
  
  = 4/(4+1)
  
  = 4/5
  
  = 0.8 atau 80%

## 15) Evaluasi dengan RMSE

RMSE yang baik adalah nilai RMSE < 10% skala data.

Menggunakan nilai y yang telah dinormalisasi dari nilai book_rating, maka <10% skala data adalah:

= (max_y - min_y) * 10%

= (1 - 0) * 10%

= 0.1
"""

# Mengambil nilai minimum dan maksimum y
nilai_min_y = min(y)
nilai_max_y = max(y)

# Benchmark atau patokan nilai rmse pada data ini
benchmark = (nilai_max_y - nilai_min_y) * 0.1

# Nilai prediksi
y_pred = model.predict(x_val)

# Nilai RMSE dari prediksi
rmse = mean_squared_error(y_val, y_pred, squared=False)

# Menampilkan hasil
print("Nilai min y = ", nilai_min_y)
print("Nilai max y = ", nilai_max_y)
print("Nilai benchmark = ", benchmark)
print("Nilai RMSE = ", rmse)
if(rmse < benchmark):
  print("Nilai RMSE model sudah baik.")
else:
  print("Nilai RMSE model belum cukup baik.")